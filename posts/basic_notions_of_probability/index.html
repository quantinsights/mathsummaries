<!DOCTYPE html>
<html lang="en-us">
<title>Basic_notions_of_probability | Math Summaries</title>
<meta charset="utf-8">
<meta name="generator" content="Hugo 0.92.0" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="stylesheet" href="https://quantophile.github.io/mathsummaries/css/index.css">
<link rel="canonical" href="https://quantophile.github.io/mathsummaries/posts/basic_notions_of_probability/">
<link rel="alternate" type="application/rss+xml" href="" title="Math Summaries">

<header>
  
    <a href="https://quantophile.github.io/mathsummaries/" class="title">Math Summaries</a>
  
  
</header>

<article>
  <header>
    <h1>Basic_notions_of_probability</h1>
    <time datetime="2022-02-11T21:22:12&#43;01:00">February 11, 2022</time>
  </header>
  <p>In this post, we review the basic notions of probability that will be needed to study Stochastic Calculus.</p>
<h2 id="probability-space">Probability Space.</h2>
<p>Probability theory provides a framework to study random experiments, that is, experiments where the exact outcome cannot be predicted accurately. Such random experiments involve a source of randomness. Elementary random experiments include the roll of the die and consecutive coin tosses. In applications, the source of randomness could be, for example, all the transactions that take place at the New York Stock Exchange in a given time, the times of decay of radioactive material, and pseudorandom numbers generated by a computer.</p>
<p>The theoretical framework of a random experiment is as follows.</p>
<p>Assume that $(f_n)$ is a sequence of continuous functions on a set $A \subseteq \mathbf{R}$, and assume $(f_n)$ converges pointwise to a limit $f$. To argue that $f$ is continuous, fix a point $c \in A$, and let $\epsilon &gt; 0$. To argue that $f$ is continuous, fix a point $c \in A$, and let $\epsilon &gt; 0$. We need to find a $\delta &gt; 0$ such that</p>
<p>$$
|x - c| &lt; \delta \implies |f(x) - f(c)| &lt; \epsilon
$$</p>
<p>By the triangle inequality,</p>
<p>$$
\begin{align*}
|f(x) - f(c)| &amp;= |f(x) - f_n(x) + f_n(x) - f_n(c) + f_n(c) - f(c)|\\
&amp;\leq |f(x) - f_n(x)| + |f_n(x) - f_n(c)| + |f_n(c) - f(c)|
\end{align*}
$$</p>
<p>Our first, optimistic impression is that each term in the sum of the right-hand side can be made small - the first and third by the fact that $f_n \to f$, and the middle term by the continuity of $f_n$. In order to use the continuity of $f_n$, we must first establish which particular $f_n$ we are talking about. Our first, optimistic impression is that each term in the sum on the right-hand can be small - the first and third by the fact that $f_n \to f$, and the middle term by the continuity of $f_n$. In order to use the continuity of $f_n$, we must first establish which particular $f_n$ we are talking about. Because $c \in A$ is fixed, there exists $N(\epsilon/3,c)$ such that</p>
<p>$$
|f_N(x) - f_N(c) &lt; \frac{\epsilon}{3}
$$</p>
<p>for all $x$ satisfying $|x-c|&lt;\delta$.</p>
<p>Not that $N$ is chosen, the continuity of $f_N$ at $c$ implies that there exists $\delta(N,\epsilon/3) &gt; 0$ such that</p>
<p>$$
|f_N(x) - f_N(c)|&lt; \frac{\epsilon}{3}
$$</p>
<p>for all $x$ satisfying $|x - c| &lt; \delta$.</p>
<p>But, here is the problem. We also need
$$
|f_N(x) - f(x)| &lt; \frac{\epsilon}{3}
$$</p>
<p>That is, for an arbitrary point $x$, it might very well be the case that, $f_{P} - f(x)&lt;\epsilon/3$, where $P &gt; N$. More, to the point, the variable $x$ is not fixed the way $c$ is in this discussion but represents any point in the interval $(c-\delta,c+\delta)$. Pointwise convergence implies that we can make $|f_n(x) - f(x)| &lt; \epsilon/3$ for large enough values of $n$, but <em>the value of $n$ depends on the point $x$</em>. It is possible that different values of $x$ will result in the need for different - larger - choices of $n$. So, the set</p>
<p>$$\{N \in \mathbf{N}:|f_N(x) - f(x)|&lt;\epsilon \text{ for all }x \in V_{\epsilon/3}(c)\}$$</p>
<p>can be an unbounded set.</p>
<h3 id="uniform-convergence">Uniform Convergence.</h3>
<p>To resolve this dilemma, we define a new, stronger notion of convergence of functions.</p>
<hr>
<p><strong>Definition. (Uniform Convergence).</strong> Let $(f_n)$ be a sequence of functions defined on a set $A \subseteq \mathbf{R}$. Then, $(f_n)$ <em>converges uniformly</em> on $A$ to a limit function $f$ defined on $A$ if and only if, for all $\epsilon &gt; 0$, there exists $N = N(\epsilon)$, such that $|f_n(x) - f(x)|&lt;\epsilon$ for all $n \geq N$ and $x \in A$. Mathematically,</p>
<p>$$: (\forall \epsilon &gt;0), (\exists N(\epsilon) \in \mathbf{N}) : |f_n(x) - f(x)|&lt;\epsilon, \forall x \in A, \forall n \geq N$$</p>
<hr>
<p>To emphasize the difference between uniform convergence and pointwise convergence, we restate the definition of pointwise convergence being more explicit about the relationship between $\epsilon$, $N$ and $x$. In particular, notice where the domain point $x$ is referenced in each definition and consequently how the choice of $N$ then does or does not depend on this value.</p>
<hr>
<p><strong>Definition (Pointwise Convergence).</strong> Let $f_n$ be a sequence of functions defined on a set $A \subseteq \mathbf{R}$. Then, $(f_n)$ <em>converges  pointwise</em> on $A$ to a limit $f$ defined on $A$ if, for every $\epsilon &gt; 0$ and for all $x \in A$, there exists $N=N(\epsilon,x)$ such that $|f_n(x) - f(x)| &lt; \epsilon$ for all $n \geq N$. Mathematically,</p>
<p>$$: (\forall \epsilon &gt;0), (\forall x \in A), (\exists N(\epsilon, x) \in \mathbf{N}) : |f_n(x) - f(x)|&lt;\epsilon, \forall n \geq N$$</p>
<hr>
<p>The use of the adverb <em>uniformly</em> here should be reminiscient of its use in the phrase uniformly continuous from Chapter 4. In both cases, the term uniformly is employed to express the fact that the response $\delta$ or $N$ to a prescribed $\epsilon$ can be chosen to work simultaneously for all values of $x$ in the relevant domain.</p>
<p><strong>Example.</strong> (i) Let</p>
<p>$$
g_n(x) = \frac{1}{n(1+x^2)}
$$</p>
<p>For any fixed $x \in \mathbf{R}$, we can see that $\lim g_n(x) = 0$ is the pointwise limit of the sequence $(g_n)$ on $\mathbf{R}$. Is this convergence uniform? The observation that,</p>
<p>$$
\frac{1}{1 + x^2} \leq 1
$$</p>
<p>for all $x \in \mathbf{R}$ implies that</p>
<p>$$
|g_n(x) - g(x)| = \left|\frac{1}{n(1+x^2)} - 0\right| \leq \frac{1}{n}
$$</p>
<p>Thus, given $\epsilon &gt; 0$, we can choose $N &gt; 1/\epsilon$ (which does not depend on $x$), and it follows that</p>
<p>$$
n \geq N \quad \text{ implies } \quad |g_n(x) - g(x)| &lt; \epsilon
$$</p>
<p>for all $x \in \mathbf{R}$. By definition, $g_n \to 0$ uniformly on $\mathbf{R}$.</p>
<p>(ii) Look back at example 6.2.2 (i), where we saw that $f_n(x) = (x^2 + nx)/n$ converges pointwise on $\mathbf{R}$ to $f(x) = x$. On $\mathbf{R}$, the convergence is not uniform. To see this write</p>
<p>$$
|f_n(x) - f(x)| = \left|\frac{x^2 + nx}{n} - x\right| = \frac{x^2}{n}
$$</p>
<p>and notice that in order to force $|f_n(x) - f(x)|&lt;\epsilon$, we are going to have to choose</p>
<p>$$
N &gt; \frac{x^2}{\epsilon}
$$</p>
<p>Although this is possible to do for each $x \in \mathbf{R}$, there is not way to choose a single value of $N$ that will work for all values of $x$ at the same time.</p>
<p>On the other hand, we can show that $f_n \to f$ uniformly on the set $[-b,b]$. By restricting our attention to a bounded interval, we may now assert that</p>
<p>$$
\frac{x^2}{n} \leq \frac{b^2}{n}
$$</p>
<p>Given $\epsilon &gt; 0$ then, we can choose:</p>
<p>$$
N &gt; \frac{b^2}{\epsilon}
$$</p>
<p>Graphically speaking, the uniform convergence of $f_n$ to a limit $f$ on a set $A$ can be visualized by constructing a band of radius $\pm \epsilon$ around the limit function $f$. If $f_n \to f$ uniformly, then there exists a point in the sequence after which each $f_n$ is <em>completely</em> contained in this $\epsilon-$strip.</p>
<h3 id="cauchy-criterion">Cauchy Criterion</h3>
<p>Recall that the Cauchy criterion for convergent sequences of real numbers was an equivalent characterization of convergence which, unlike the definition, did not make explicit mention of the limit. The usefulness of the Cauchy criterion suggests the need for an analogous characterization of uniformly convergent sequences of functions. As with all statements about uniformity, pay special attention to the relationship between the response variable ($N \in \mathbf{N}$) and the domain variable ($x \in A$).</p>
<hr>
<p><strong>Theorem (Cauchy Criterion for Uniform Convergence).</strong> A sequence of functions $(f_n)$ defined on a set $A \subseteq \mathbf{R}$ converges uniformly on $A$, if and only if, for every $\epsilon &gt; 0$ there exists $N \in \mathbf{N}$ such that $|f_n(x) - f_m(x)| &lt; \epsilon$ whenever $m,n \geq N$ and $x \in A$.</p>
<hr>
<h3 id="continuity-revisited">Continuity Revisited</h3>
<p>The stronger assumption of uniform convergence is precisely what is required to remove the flaws from our attempted proof that the limit of continuous functions is continuous.</p>
<hr>
<p><strong>Theorem (Continuous Limit Theorem).</strong> Let $(f_n)$ be a sequence of functions defined on $A \subseteq \mathbf{R}$ that converges uniformly on $A$ to a function $f$. If each $f_n$ is continuous at $c \in A$, then $f$ is continuous at $c$.</p>
<hr>
<p><em>Proof.</em> Fix $c \in A$ and let $\epsilon &gt; 0$. Choose $N(\epsilon)$ so that:</p>
<p>$$
|f_N(x) - f(x)| &lt; \frac{\epsilon}{3}
$$</p>
<p>for all $x \in A$. We are able to do so, because $(f_n)$ converges to $f$ uniformly. Because $f_N$ is continuous, there exists $\delta(\epsilon,N,c)&gt;0$ for which</p>
<p>$$
f_N(x) - f_N(c)| &lt; \frac{\epsilon}{3}
$$</p>
<p>for all $|x - c| &lt; \delta$.</p>
<p>And finally, since $(f_n)$ uniformly converges to $f$ on $A$, for the same $N(\epsilon)$, it follows that</p>
<p>$$
f_N(c) - f(c)| &lt; \frac{\epsilon}{3}
$$</p>
<p>This implies that,</p>
<p>$$
\begin{align*}
|f(x) - f(c)| &amp;= |f(x) - f_N(x) + f_N(x) - f_N(c) + f_N(c) - f(c)|\\
&amp;\leq |f(x) - f_N(x)| + |f_N(x) - f_N(c)| + |f_N(c) - f(c)|\\
&amp;&lt; \frac{\epsilon}{3} + \frac{\epsilon}{3} + \frac{\epsilon}{3} = \epsilon
\end{align*}
$$</p>
<p>Thus, $f$ is continuous at $c \in A$.</p>
<h3 id="exercise-problems">Exercise Problems.</h3>
<hr>
<ol>
<li>[Abbott 6.2.1] Let</li>
</ol>
<p>$$f_n(x) = \frac{nx}{1 + nx^2}$$</p>
<p>(a) Find the pointwise limit of $(f_n)$ for all $x \in (0,\infty)$.</p>
<p>(b) Is the convergence uniform on $(0,\infty)$?</p>
<p>(c) Is the convergence uniform on $(0,1)$?</p>
<p>(d) Is the convergence uniform on $(1,\infty)$?</p>
<hr>
<p><em>Proof.</em></p>
<p>(a) We have,</p>
<p>$$
\begin{align*}
\lim_{n \to \infty} f_n(x) &amp;= \lim_{n \to \infty} \frac{nx}{1 + nx^2} =\lim_{n \to \infty}  \frac{x}{\frac{1}{n} + x^2} \\
&amp;= \frac{x}{x^2} = \frac{1}{x}
\end{align*}
$$</p>
<p>Define</p>
<p>$$
f(x) = \frac{1}{x}
$$</p>
<p>Then, $(f_n)$ converges pointwise to $f$.</p>
<p>(b) Consider the distance</p>
<p>$$
\begin{align*}
|f_n(x) - f(x)| &amp;= \left|\frac{nx}{1 + nx^2} - \frac{1}{x}\right| = \left|\frac{nx^2 - 1 - nx^2}{x(1+nx^2)}\right|\\
&amp;= \left|\frac{1}{x(1+nx^2)}\right|\\
&amp;\leq \frac{1}{n|x|^3}
\end{align*}
$$</p>
<p>We are interested to make the above distance as small as we please. So, we must $N &gt; \frac{|x|^3}{\epsilon}$. Here, $N$ is function of both the point $x$ and $\epsilon$. We cannot choose a single $N$, that works for all $x$. Hence, $(f_n)$ does not converge uniformly to $f$ on $(0,\infty)$.</p>
<p>(c) $(f_n)$ does not converge uniformly to $f$ on $(0,1)$.</p>
<p>(d) We have,</p>
<p>$$
N &gt; \frac{|x|^3}{\epsilon}
$$</p>
<p>If we replace the right hand by it&rsquo;s lower bound, we are strengthening the condition we wish to prove. Since $x \in (1,\infty)$, we have $|x| &gt; 1$. So, pick</p>
<p>$$
N &gt; \frac{1}{\epsilon}
$$</p>
<p>It follows that, $(f_n)$ converges to $f$ uniformly.</p>
<hr>
<ol start="2">
<li>[Abbott 6.2.2] (a) Define a sequence of functions on $\mathbf{R}$ by,</li>
</ol>
<p>$$
f_n(x) = \begin{cases}
1 &amp;\text{ if } x = 1,\frac{1}{2},\frac{1}{3},\ldots,\frac{1}{n}\\
0 &amp;\text{ otherwise }
\end{cases}
$$</p>
<p>and let $f$ be the pointwise limit of $f_n$. Is each $f_n$ continuous at zero? Does $f_n \to f$ uniformly on $\mathbf{R}$? Is $f$ continuous at zero?</p>
<p>(b) Repeat this exercise using the sequence of functions</p>
<p>$$
g_n(x) = \begin{cases}
x \quad \text{ if } x = 1,\frac{1}{2}, \frac{1}{3}, \ldots,\frac{1}{n}\\
0 \quad \text{ otherwise }
\end{cases}
$$</p>
<p>(c) Repeat the exercise once more with the sequence</p>
<p>$$
h_n(x) = \begin{cases}
1 \quad \text{ if } x = \frac{1}{n} \\
x \quad \text{ if } x = 1, \frac{1}{2},\frac{1}{3},\ldots,\frac{1}{n-1} \\
0 \quad \text{ otherwise }
\end{cases}
$$</p>
<p>In each case, explain how the results are consistent with the content of the Continuous Limit Theorem.</p>
<hr>
<p><em>Proof</em>.</p>
<p>(a)</p>
<p>Define</p>
<p>$$
f(x) = \begin{cases}
1 &amp;\text{ if } x \in \{\frac{1}{n}:n \in \mathbf{N}\} \\
0 &amp;\text{ otherwise }
\end{cases}
$$</p>
<p><strong>Pointwise convergence.</strong></p>
<p>We show that, $(f_n)$ converges to $f$ pointwise for all $x$.</p>
<p>Let $x \in \{ \frac{1}{n}:n\in\mathbf{N}\}$.</p>
<p>Pick an arbitrary $\epsilon &gt; 0$. By the Archimedean property, there exists an $N \in \mathbf{N}$ such that $\frac{1}{N} &lt; \epsilon$.</p>
<p>If we choose $M &gt; N + 1$, then $\frac{1}{M} &lt; \frac{1}{N+1} &lt; \epsilon$. The distance</p>
<p>$$
|f_m(x) - f(x)| = |1 - 1| = 0 &lt; \epsilon
$$</p>
<p>for all $m \geq M$ and $x \in \{ \frac{1}{n}:n\in\mathbf{N}\}$. Moreover, if $x$ does not belong to this set, then $|f_m(x) - f(x)| = |0 - 0| &lt; \epsilon$.</p>
<p><strong>Uniform convergence.</strong></p>
<p>$(f_n)$ does not converge uniformly to $f$. Carefully, negating the definition of uniform convergence, we have,</p>
<hr>
<p><strong>Absence of uniform convergence.</strong> Let $(f_n)$ be a sequence of functions defined on a set $A\subseteq \mathbf{R}$. Then, $(f_n)$ fails to converge uniformly on $A$ to $f$, if, there exists $\epsilon_0 &gt; 0$, for all $N$, such that $|f_n(x) - f(x)| \geq \epsilon_0$ for atleast one $n \geq N$ and some $x \in A$.</p>
<hr>
<p>Pick $\epsilon_0 = \frac{1}{2}$ and $x_0 \in \{\frac{1}{n}:n \in \mathbf{N}, n &gt; N\}$. Then, $|f_N(x_0) - f(x_0)| = |0 - 1| = 1 &gt; \frac{1}{2} = \epsilon_0$.</p>
<p><strong>Continuity of $f_n$.</strong></p>
<p>$f_M$ is continuous at $c = 0$. Pick an arbitrary $\epsilon &gt; 0$. By the Archimedean property, there exists a natural number $N \in\mathbf{N}$ such that, $N &lt; \frac{1}{\epsilon}$. We are interested to make the distance $|f_M(x) - f_M(0)| &lt; \frac{1}{N}$. Pick $\delta = \min \{\frac{1}{2M},\frac{1}{2N}\}$. Then, for all $x \in (-\delta,\delta)$, it follows that $|f_M(x) - f_M(0)| = |0 - 0| = 0 &lt;\epsilon$.</p>
<p><strong>Continuity of $f$.</strong></p>
<p>$f$ is not continuous at $c = 0$. Consider the sequence $(x_n)$ defined by $x_n:= \frac{1}{n}$. We have, $(x_n) \to 0$. But, $f(x_n)$ is the sequence $(1,1,1,\ldots)$, which converges to $1$, whilst $f(0)= 0$. So, $f$ fails to be continuous at $c=0$.</p>
<p>(b) Define</p>
<p>$$
g(x) = \begin{cases}
x \quad \text{ if } x \in \{\frac{1}{n} : n \in \mathbf{N}\}\\
0 \quad \text{ otherwise }
\end{cases}
$$</p>
<p><strong>Pointwise convergence.</strong></p>
<p>Pick an arbitrary $\epsilon &gt; 0$. By the Archimedean property, there exists $N \in\mathbf{N}$, such that, $\frac{1}{N} &lt; \epsilon$.</p>
<p>Let $x \in \{\frac{1}{n}:n\in\mathbf{N}\}$.</p>
<p>If $n &lt; N$, then $x = \frac{1}{n} &gt; \frac{1}{N}$. Pick $M &gt; N + 1$, then $\frac{1}{M} &lt; \frac{1}{N} &lt; x$. Thus, $|g_m(x) - g(x)| = |x - x| = 0 &lt; \frac{1}{N} &lt; \epsilon$ for all $m \geq M$.</p>
<p>If $n &gt; N$, then $x = \frac{1}{n} &lt; \frac{1}{N}$. Again, pick $M &gt; \left(\frac{1}{x} + 1\right)$. Then, $\frac{1}{M} &lt; x &lt; \frac{1}{N}$. Thus, $|g_m(x) - g(x)| = |x - x| = 0 &lt; \epsilon$ for all $m \geq M$.</p>
<p>Consequently, $(g_n)$ converges pointwise to $g$.</p>
<p><strong>Uniform convergence.</strong></p>
<p>Consider an arbitrary $g_N(x)$. And sample $g_N(x)$ at $x = \frac{1}{n}$, $n \in\mathbf{N}$. We have,</p>
<p>$$
g_N(1) = 1, g_N\left(\frac{1}{2}\right) = \frac{1}{2}, g_N\left(\frac{1}{3}\right) = \frac{1}{3},\ldots, g_N\left(\frac{1}{N}\right) = \frac{1}{N}, g_N\left(\frac{1}{N+1}\right) = 0
$$</p>
<p>And,</p>
<p>$$
g(1) = 1, g\left(\frac{1}{2}\right) = \frac{1}{2}, g\left(\frac{1}{3}\right) = \frac{1}{3},\ldots, g\left(\frac{1}{N}\right) = \frac{1}{N}, g\left(\frac{1}{N+1}\right) = \frac{1}{N+1}
$$</p>
<p>So, $\sup_x |g_N(x) - g(x)| = \frac{1}{N+1}$.</p>
<p>If we pick, $N &gt; \frac{1}{\epsilon}$, then $|g_n(x) - g(x)| &lt; \epsilon$ for all $x \in A$ and for all $n \geq N$. Consequently, $(g_n)$ converges uniformly to $g$ on $\mathbf{R}$.</p>
<p><strong>Continuity of $g_n$.</strong></p>
<p>$(g_n)$ is continuous at $c = 0$.</p>
<p><strong>Continuity of $g$.</strong></p>
<p>By continuous limit theorem, since $(g_n)$ converges uniformly to $g$, and each $g_n$ is continuous at $c=0$, it follows that $g$ is continuous at $c = 0$.</p>
<p>$g$ is continuous at $c = 0$. Pick an arbitrary $\epsilon &gt; 0$. Let $(x_n)$ be an arbitrary sequence, such that $(x_n) \to 0$, with $x_n \neq 0$. The image sequence $g(x_n) = (x_n)$, which converges to $0$. This is true for all sequences $(x_n)$. Consequently, $g$ is continuous at $c = 0$.</p>
<p>(c) Define</p>
<p>$$
h(x) = \begin{cases}
x &amp;\text{ if } x \in \{\frac{1}{n}:n\in\mathbf{N}\}\\
0 &amp;\text{ otherwise }
\end{cases}
$$</p>
<p><strong>Pointwise convergence.</strong></p>
<p>Pick an arbitrary $\epsilon &gt; 0$. By the Archimedean property, there exists $N &gt; 0$ such that $\frac{1}{N} &lt; \epsilon$.</p>
<p>Let $x \in \{\frac{1}{n}:n \in \mathbf{N} \}$.</p>
<p>Pick $M &gt; \max \{N+1, \frac{1}{x}\}$. Then, the distance $|h_m(x) - h(x)|=|x - x| = 0 &lt;\epsilon$ for all $m \geq M$ and $x \in (0,\infty)$. Consequently, $(h_m)$ converges to $h$ pointwise.</p>
<p><strong>Uniform convergence.</strong></p>
<p>Pick $\epsilon_0 = \frac{1}{2}$. If $M = 1$, pick $x_0 = 1/2$, we have $|h_2(1/2) - h(1/2)| = 1 - \frac{1}{2} \geq \frac{1}{2}$. If $M \geq 2$, pick $x_0 = \frac{1}{M}$, for all $M \in \mathbf{N}$. Then, $|h_M(x_0) - h(x_0)|=1 - \frac{1}{M} \geq \frac{1}{2} = \epsilon_0$.</p>
<p>Consequently, $(h_m)$ does not converge uniformly to $h$.</p>
<p><strong>Continuity of $(h_n)$.</strong></p>
<p>$h_n$ is continuous at $c = 0$.</p>
<p><strong>Continuity of $h$.</strong></p>
<p>$h$ is continuous at $c = 0$.</p>
<hr>
<ol start="3">
<li>[Abbott 6.2.3] For each $n \in \mathbf{N}$ and $x \in [0,\infty)$, let</li>
</ol>
<p>$$
g_n(x) = \frac{x}{1 + x^n} \quad \text{ and } \quad h_n(x) = \begin{cases}
1 &amp; \text{ if } x \geq 1/n \\
nx &amp; \text{ if } 0 \leq x &lt; 1/n
\end{cases}
$$</p>
<p>Answer the following questions for the sequences $(g_n)$ and $(h_n)$:</p>
<p>(a) Find the pointwise limit on $[0,\infty)$.</p>
<p>(b) Explain how we know that the convergence <em>cannot</em> be uniform on $[0,\infty)$.</p>
<p>(c) Choose a smaller set over which the convergence is uniform and supply an argument to show that this is indeed the case.</p>
<hr>
<p><em>Proof.</em></p>

</article>



</html>
